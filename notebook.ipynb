{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and decoding\n",
    "def decode(vocab,corpus):\n",
    "    \n",
    "    text = ''\n",
    "    for i in range(len(corpus)):\n",
    "        wID = corpus[i]\n",
    "        text = text + vocab[wID] + ' '\n",
    "    return(text)\n",
    "\n",
    "def encode(words,text):\n",
    "    corpus = []\n",
    "    tokens = text.split(' ')\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            wID = words[t][0]\n",
    "        except:\n",
    "            wID = words['<unk>'][0]\n",
    "        corpus.append(wID)\n",
    "    return(corpus)\n",
    "\n",
    "def read_encode(file_name,vocab,words,corpus,threshold):\n",
    "    \n",
    "    wID = len(vocab)\n",
    "    \n",
    "    if threshold > -1:\n",
    "        with open(file_name,'rt', encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                line = line.replace('\\n','')\n",
    "                tokens = line.split(' ')\n",
    "                for t in tokens:\n",
    "                    try:\n",
    "                        elem = words[t]\n",
    "                    except:\n",
    "                        elem = [wID,0]\n",
    "                        vocab.append(t)\n",
    "                        wID = wID + 1\n",
    "                    elem[1] = elem[1] + 1\n",
    "                    words[t] = elem\n",
    "\n",
    "        temp = words\n",
    "        words = {}\n",
    "        vocab = []\n",
    "        wID = 0\n",
    "        words['<unk>'] = [wID,100]\n",
    "        vocab.append('<unk>')\n",
    "        for t in temp:\n",
    "            if temp[t][1] >= threshold:\n",
    "                vocab.append(t)\n",
    "                wID = wID + 1\n",
    "                words[t] = [wID,temp[t][1]]\n",
    "            \n",
    "                    \n",
    "    with open(file_name,'rt', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n','')\n",
    "            tokens = line.split(' ')\n",
    "            for t in tokens:\n",
    "                try:\n",
    "                    wID = words[t][0]\n",
    "                except:\n",
    "                    wID = words['<unk>'][0]\n",
    "                corpus.append(wID)\n",
    "                \n",
    "    return [vocab,words,corpus]\n",
    "\n",
    "def plot_data(x, y, xlabel, ylabel):\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(bios, targets):\n",
    "    zipped_data = list(zip(bios, targets))\n",
    "    text_df = pd.DataFrame(zipped_data, columns=['Bios', 'Labels'])\n",
    "    return text_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def process_data(data):\n",
    "    fake_i = (data == 122)\n",
    "    real_i = (data == 635)\n",
    "    target_indices = (fake_i + real_i).nonzero()\n",
    "    num_entries = len(target_indices)\n",
    "    bio_tensor_list = []\n",
    "    target_list = []\n",
    "    entry = 0\n",
    "    start_i = 0\n",
    "\n",
    "    while entry < num_entries:\n",
    "        target_i = target_indices[entry]\n",
    "\n",
    "        # Size of data and targets\n",
    "        #print(f\"Data size: {data[start_i:target_i].size()}\")\n",
    "        #print(f\"Target size: {data[target_i].size()}\")\n",
    "\n",
    "        # Take in a list of tensors and use pad sequence\n",
    "        bio = data[start_i:target_i]\n",
    "        target = [1, 0] if data[target_i] == 122 else [0, 1]\n",
    "\n",
    "        bio_tensor_list.append(torch.tensor(bio).squeeze())\n",
    "        target_list.append(target)\n",
    "\n",
    "        start_i = target_i + 1\n",
    "        entry += 1\n",
    "\n",
    "    padded_bios = torch.t(pad_sequence(bio_tensor_list))\n",
    "    targets = torch.tensor(target_list)\n",
    "\n",
    "    # print(\"First bio\", padded_bios[0].size())\n",
    "    # print(\"Second bio\", padded_bios[1].size())\n",
    "    data_df = create_df(padded_bios, targets)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_df):\n",
    "        self.text_df = data_df\n",
    "        print(\"Head of Data\", self.text_df.head())\n",
    "        self.x = self.text_df['Bios']\n",
    "        self.y = self.text_df['Labels']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeedForward Model\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, vocab, words, d_model, d_hidden, dropout):\n",
    "        super().__init__() \n",
    "    \n",
    "        # Class parameters\n",
    "        self.vocab = vocab\n",
    "        self.words = words\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.d_model = d_model\n",
    "        self.d_hidden = d_hidden\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embeds = nn.Embedding(self.vocab_size, self.d_model)\n",
    "\n",
    "        # Linear Layers\n",
    "        self.fc1 = nn.Linear(880 * d_model, d_hidden)\n",
    "        self.fc2 = nn.Linear(d_hidden, 2)\n",
    "\n",
    "        # Nonlinear Layer\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        # Setting weights\n",
    "        self.init_weights()\n",
    "                \n",
    "    # Initialize weights for foward layer\n",
    "    def init_weights(self):\n",
    "        weight_range = 0.1\n",
    "        self.embeds.weight.data.uniform_(-weight_range, weight_range)\n",
    "        self.fc1.weight.data.uniform_(-weight_range, weight_range)\n",
    "        self.fc1.bias.data.zero_()\n",
    "\n",
    "    # Forward\n",
    "    def forward(self, src):\n",
    "        # Embeddings are fed into the forward layer\n",
    "        embeds = self.embeds(src).view((-1, 880 * self.d_model))\n",
    "        x = self.activation(self.fc1(embeds))\n",
    "        x = self.fc2(x)\n",
    "        # probs = nn.Softmax(x)\n",
    "        # print(\"probs\", probs)\n",
    "        # return probs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,vocab,words,d_model,d_hidden,n_layers,dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Class Parameters\n",
    "        self.vocab = vocab\n",
    "        self.words = words\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.n_layers = n_layers\n",
    "        self.d_hidden = d_hidden\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embeds = nn.Embedding(self.vocab_size,self.d_model)\n",
    "        \n",
    "    # Forward\n",
    "    def forward(self,src,h):\n",
    "        embeds = self.dropout(self.embeds(src))       \n",
    "        return [preds,h]\n",
    "    \n",
    "    def init_weights(self):\n",
    "        pass        \n",
    "    \n",
    "    def detach_hidden(self, hidden):\n",
    "        return [hidden, cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Batch Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model Function\n",
    "def train_model(model, data_loader, optimizer, criterion):\n",
    "        #print(data.size())\n",
    "        cur_loss = 0\n",
    "\n",
    "        for batch_idx, (train_features, train_labels) in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            logit_output = model(train_features).squeeze()\n",
    "            probs = torch.softmax(logit_output, dim=1)\n",
    "            loss = criterion(probs.float(), train_labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            cur_loss += loss.item()\n",
    "            if batch_idx % 10 == 0:\n",
    "                prev_loss = cur_loss / 10\n",
    "                cur_loss = 0\n",
    "\n",
    "        # Shapes of output and targets\n",
    "        # print(f\"Output size: {probs.size()}\")\n",
    "        # print(f\"Target size: {train_labels.size()}\")\n",
    "\n",
    "        # loss = F.mse_loss(output.float(), targets.float())\n",
    "        # output = torch.argmax(output, dim=1)\n",
    "\n",
    "        return prev_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, data_df, epochs, optimizer, criterion):\n",
    "\n",
    "    data = TextDataset(data_df)\n",
    "    train_dataloader = DataLoader(data, batch_size=64, shuffle=True)\n",
    "    average_loss_list = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "        model.train(True)\n",
    "        average_loss = train_model(model, train_dataloader, optimizer, criterion)\n",
    "        model.train(False)\n",
    "\n",
    "        average_loss_list.append(average_loss)\n",
    "        epoch_list.append(epoch)\n",
    "        print(f\"Epoch {epoch}\")\n",
    "\n",
    "    plot_data(epoch_list, average_loss_list, 'Epoch', 'Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Loading Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "            \n",
    "model_map = {0: 'FFNN', 1: 'LSTM', 2: 'FFNN_CLASSIFY', 3: 'LSTM_CLASSIFY'}\n",
    "train_map = {0: 'data/real.train.tok', 1: 'data/fake.train.tok', 2: 'data/mix.train.tok'}\n",
    "valid_map = {0: 'data/real.valid.tok', 1: 'data/fake.valid.tok', 2: 'data/mix.valid.tok'}\n",
    "test_map = {0: 'data/real.test.tok', 1: 'data/fake.test.tok', 2: 'data/mix.test.tok', 3: 'data/blind.test.tok'}\n",
    "\n",
    "model_type = model_map[0]\n",
    "# train_type = [train_map[0], train_map[1]]\n",
    "\n",
    "# Types of data\n",
    "train_type = train_map[2]\n",
    "valid_type = valid_map[0]\n",
    "test_type = test_map[0]\n",
    "\n",
    "args = {\n",
    "    \"d_model\": 1,\n",
    "    \"d_hidden\": 2,\n",
    "    \"n_layers\": 3,\n",
    "    \"batch_size\": 20,\n",
    "    \"seq_len\": 30,\n",
    "    \"printevery\": 5000,\n",
    "    \"window\": 3,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 0.0001,\n",
    "    \"dropout\": 0.35,\n",
    "    \"clip\": 2.0,\n",
    "    \"model\": model_type,\n",
    "    \"savename\": model_type.lower(),\n",
    "    \"loadname\": model_type.lower(),\n",
    "    \"trainname\": train_type,\n",
    "    \"validname\": valid_type,\n",
    "    \"testname\": test_type\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function\n",
    "def main(args): \n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    params = Params(**args)\n",
    "    train_name = params.trainname\n",
    "    test_name = params.testname\n",
    "    model_type = params.model\n",
    "    d_mod = params.d_model\n",
    "    d_hid = params.d_hidden\n",
    "    dropout = params.dropout\n",
    "    epochs = params.epochs\n",
    "\n",
    "    # real, fake = params.trainname\n",
    "    # [vocab_real, words_real, train_real] = read_encode(real, [], {}, [], 3)\n",
    "    # [vocab_fake, words_fake, train_fake] = read_encode(fake, [], {}, [], 3)\n",
    "\n",
    "    # train_features = torch.cat((torch.tensor(train_real), torch.tensor(train_fake)))\n",
    "    # train_labels = torch.cat((torch.ones(len(train_real)), torch.zeros(len(train_fake))))\n",
    "    # print(f'train_features: {train_features}')\n",
    "    # print(f'train_labels: {train_labels}')\n",
    "\n",
    "    [vocab,words,train] = read_encode(train_name,[],{},[],3)\n",
    "    train_data = torch.tensor(train)\n",
    "    \n",
    "    # print('vocab: %d train: %d' % (len(vocab),len(train)))\n",
    "    # print(f'vocab: {vocab[10:20]}\\n \\n train: {train[10:20]}')\n",
    "    # print(f'fake id: {words[\"[FAKE]\"]}')\n",
    "    # print(f'real id: {words[\"[REAL]\"]}')\n",
    "\n",
    "    [vocab,words,test] = read_encode(test_name,vocab,words,[],-1)\n",
    "    test_data = torch.tensor(test)\n",
    "\n",
    "    #print('vocab: %d test: %d' % (len(vocab),len(test)))\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "    train_df = process_data(train_data)\n",
    "    #test_df = process_data(test_data, test_name)\n",
    "    \n",
    "    if model_type == 'FFNN':\n",
    "        ffnn_model = FFNN(vocab, words, d_mod, d_hid, dropout)\n",
    "        optimizer = torch.optim.SGD(ffnn_model.parameters(), lr=0.01, momentum=0.9)\n",
    "        criterion = nn.BCELoss()\n",
    "        train_loop(ffnn_model, train_df, epochs, optimizer, criterion)\n",
    "        pass\n",
    "        # print(ffnn_model)\n",
    "#          {add code to instantiate the model, train for K epochs and save model to disk}\n",
    "        \n",
    "    if model_type == 'LSTM':\n",
    "        pass\n",
    "#          {add code to instantiate the model, train for K epochs and save model to disk}\n",
    "\n",
    "    if model_type == 'FFNN_CLASSIFY':\n",
    "        pass\n",
    "#          {add code to instantiate the model, recall model parameters and perform/learn classification}    \n",
    "\n",
    "    if model_type == 'LSTM_CLASSIFY':\n",
    "        pass\n",
    "#          {add code to instantiate the model, recall model parameters and perform/learn classification}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Running Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zarif_vfgx7yn\\AppData\\Local\\Temp\\ipykernel_13152\\865378823.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_tensor_list.append(torch.tensor(bio).squeeze())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of Data                                                 Bios                  Labels\n",
      "0  [tensor(1), tensor(2), tensor(3), tensor(4), t...  [tensor(1), tensor(0)]\n",
      "1  [tensor(1), tensor(2), tensor(3), tensor(4), t...  [tensor(1), tensor(0)]\n",
      "2  [tensor(1), tensor(2), tensor(3), tensor(4), t...  [tensor(1), tensor(0)]\n",
      "3  [tensor(1), tensor(2), tensor(3), tensor(4), t...  [tensor(1), tensor(0)]\n",
      "4  [tensor(93), tensor(1), tensor(2), tensor(3), ...  [tensor(0), tensor(1)]\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
