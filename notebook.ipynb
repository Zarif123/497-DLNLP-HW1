{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy Contents to starter.py for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and decoding\n",
    "def decode(vocab,corpus):\n",
    "    \n",
    "    text = ''\n",
    "    for i in range(len(corpus)):\n",
    "        wID = corpus[i]\n",
    "        text = text + vocab[wID] + ' '\n",
    "    return(text)\n",
    "\n",
    "def encode(words,text):\n",
    "    corpus = []\n",
    "    tokens = text.split(' ')\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            wID = words[t][0]\n",
    "        except:\n",
    "            wID = words['<unk>'][0]\n",
    "        corpus.append(wID)\n",
    "    return(corpus)\n",
    "\n",
    "def read_encode(file_name,vocab,words,corpus,threshold):\n",
    "    \n",
    "    wID = len(vocab)\n",
    "    \n",
    "    if threshold > -1:\n",
    "        with open(file_name,'rt', encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                line = line.replace('\\n','')\n",
    "                tokens = line.split(' ')\n",
    "                for t in tokens:\n",
    "                    try:\n",
    "                        elem = words[t]\n",
    "                    except:\n",
    "                        elem = [wID,0]\n",
    "                        vocab.append(t)\n",
    "                        wID = wID + 1\n",
    "                    elem[1] = elem[1] + 1\n",
    "                    words[t] = elem\n",
    "\n",
    "        temp = words\n",
    "        words = {}\n",
    "        vocab = []\n",
    "        wID = 0\n",
    "        words['<unk>'] = [wID,100]\n",
    "        vocab.append('<unk>')\n",
    "        for t in temp:\n",
    "            if temp[t][1] >= threshold:\n",
    "                vocab.append(t)\n",
    "                wID = wID + 1\n",
    "                words[t] = [wID,temp[t][1]]\n",
    "            \n",
    "                    \n",
    "    with open(file_name,'rt', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n','')\n",
    "            tokens = line.split(' ')\n",
    "            for t in tokens:\n",
    "                try:\n",
    "                    wID = words[t][0]\n",
    "                except:\n",
    "                    wID = words['<unk>'][0]\n",
    "                corpus.append(wID)\n",
    "                \n",
    "    return [vocab,words,corpus]\n",
    "\n",
    "def plot_data(x, y, xlabel, ylabel):\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeedForward Model\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, vocab, words, d_model, d_hidden, dropout):\n",
    "        super().__init__() \n",
    "    \n",
    "        # Class parameters\n",
    "        self.vocab = vocab\n",
    "        self.words = words\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.d_model = d_model\n",
    "        self.d_hidden = d_hidden\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embeds = nn.Embedding(self.vocab_size, self.d_model)\n",
    "\n",
    "        # Linear Layers\n",
    "        self.fc1 = nn.Linear(880 * d_model, d_hidden)\n",
    "        self.fc2 = nn.Linear(d_hidden, 2)\n",
    "\n",
    "        # Nonlinear Layer\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        # Setting weights\n",
    "        self.init_weights()\n",
    "                \n",
    "    # Initialize weights for foward layer\n",
    "    def init_weights(self):\n",
    "        weight_range = 0.1\n",
    "        self.embeds.weight.data.uniform_(-weight_range, weight_range)\n",
    "        self.fc1.weight.data.uniform_(-weight_range, weight_range)\n",
    "        self.fc1.bias.data.zero_()\n",
    "\n",
    "    # Forward\n",
    "    def forward(self, src):\n",
    "        # Embeddings are fed into the forward layer\n",
    "        embeds = self.embeds(src).view((-1, 880 * self.d_model))\n",
    "        x = self.activation(self.fc1(embeds))\n",
    "        x = self.fc2(x)\n",
    "        # probs = nn.Softmax(x)\n",
    "        # print(\"probs\", probs)\n",
    "        # return probs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,vocab,words,d_model,d_hidden,n_layers,dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Class Parameters\n",
    "        self.vocab = vocab\n",
    "        self.words = words\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.n_layers = n_layers\n",
    "        self.d_hidden = d_hidden\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embeds = nn.Embedding(self.vocab_size,self.d_model)\n",
    "        \n",
    "    # Forward\n",
    "    def forward(self,src,h):\n",
    "        embeds = self.dropout(self.embeds(src))       \n",
    "        return [preds,h]\n",
    "    \n",
    "    def init_weights(self):\n",
    "        pass        \n",
    "    \n",
    "    def detach_hidden(self, hidden):\n",
    "        return [hidden, cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def process_data(data):\n",
    "    fake_i = (data == 122)\n",
    "    real_i = (data == 635)\n",
    "    target_indices = (fake_i + real_i).nonzero()\n",
    "    num_entries = len(target_indices)\n",
    "    bio_tensor_list = []\n",
    "    target_list = []\n",
    "    entry = 0\n",
    "    start_i = 0\n",
    "\n",
    "    while entry < num_entries:\n",
    "        target_i = target_indices[entry]\n",
    "        # Size of data and targets\n",
    "        #print(f\"Data size: {data[start_i:target_i].size()}\")\n",
    "        #print(f\"Target size: {data[target_i].size()}\")\n",
    "\n",
    "        # Take in a list of tensors and use pad sequence\n",
    "        bio = data[start_i:target_i]\n",
    "        target = [1, 0] if data[target_i] == 122 else [0, 1]\n",
    "        # target = data[target_i]\n",
    "\n",
    "        bio_tensor_list.append(torch.tensor(bio).squeeze())\n",
    "        target_list.append(target)\n",
    "\n",
    "        start_i = target_i + 1\n",
    "        entry += 1\n",
    "\n",
    "    padded_bios = torch.t(pad_sequence(bio_tensor_list))\n",
    "    print(\"First bio\", padded_bios[0].size())\n",
    "    print(\"Second bio\", padded_bios[1].size())\n",
    "    return padded_bios, torch.tensor(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model Function\n",
    "def train_model(model, data, targets, optimizer):\n",
    "        print(data.size())\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logit_output = model(data).squeeze()\n",
    "        probs = torch.softmax(logit_output, dim=1)\n",
    "\n",
    "        # Shapes of output and targets\n",
    "        print(f\"Output size: {probs.size()}\")\n",
    "        print(f\"Target size: {targets.size()}\")\n",
    "\n",
    "        # loss = F.mse_loss(output.float(), targets.float())\n",
    "        # output = torch.argmax(output, dim=1)\n",
    "        loss = F.binary_cross_entropy(probs.float(), targets.float())\n",
    "        print(\"Loss:\", loss)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        return loss\n",
    "\n",
    "def train_loop(model, features, targets, epochs, optimizer):\n",
    "    losses = []\n",
    "    epoch_list = []\n",
    "    for epoch in range(0, epochs):\n",
    "        loss = train_model(model, features, targets, optimizer)\n",
    "        print(epoch)\n",
    "        epoch_list.append(epoch)\n",
    "        losses.append(loss.item())\n",
    "    plot_data(epoch_list, losses, 'Loss', 'Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_map = {0: 'FFNN', 1: 'LSTM', 2: 'FFNN_CLASSIFY', 3: 'LSTM_CLASSIFY'}\n",
    "train_map = {0: 'data/real.train.tok', 1: 'data/fake.train.tok', 2: 'data/mix.train.tok'}\n",
    "valid_map = {0: 'data/real.valid.tok', 1: 'data/fake.valid.tok', 2: 'data/mix.valid.tok'}\n",
    "test_map = {0: 'data/real.test.tok', 1: 'data/fake.test.tok', 2: 'data/mix.test.tok', 3: 'data/blind.test.tok'}\n",
    "\n",
    "model_type = model_map[0]\n",
    "# train_type = [train_map[0], train_map[1]]\n",
    "\n",
    "# Types of data\n",
    "train_type = train_map[2]\n",
    "valid_type = valid_map[0]\n",
    "test_type = test_map[0]\n",
    "\n",
    "args = {\n",
    "    \"d_model\": 1,\n",
    "    \"d_hidden\": 2,\n",
    "    \"n_layers\": 3,\n",
    "    \"batch_size\": 20,\n",
    "    \"seq_len\": 30,\n",
    "    \"printevery\": 5000,\n",
    "    \"window\": 3,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 0.0001,\n",
    "    \"dropout\": 0.35,\n",
    "    \"clip\": 2.0,\n",
    "    \"model\": model_type,\n",
    "    \"savename\": model_type.lower(),\n",
    "    \"loadname\": model_type.lower(),\n",
    "    \"trainname\": train_type,\n",
    "    \"validname\": valid_type,\n",
    "    \"testname\": test_type\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function\n",
    "def main(args): \n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    params = Params(**args)\n",
    "    train_name = params.trainname\n",
    "    test_name = params.testname\n",
    "    model_type = params.model\n",
    "    d_mod = params.d_model\n",
    "    d_hid = params.d_hidden\n",
    "    dropout = params.dropout\n",
    "    epochs = params.epochs\n",
    "\n",
    "    # real, fake = params.trainname\n",
    "    # [vocab_real, words_real, train_real] = read_encode(real, [], {}, [], 3)\n",
    "    # [vocab_fake, words_fake, train_fake] = read_encode(fake, [], {}, [], 3)\n",
    "\n",
    "    # train_features = torch.cat((torch.tensor(train_real), torch.tensor(train_fake)))\n",
    "    # train_labels = torch.cat((torch.ones(len(train_real)), torch.zeros(len(train_fake))))\n",
    "    # print(f'train_features: {train_features}')\n",
    "    # print(f'train_labels: {train_labels}')\n",
    "\n",
    "    [vocab,words,train] = read_encode(train_name,[],{},[],3)\n",
    "    train_data = torch.tensor(train)\n",
    "    \n",
    "    # print('vocab: %d train: %d' % (len(vocab),len(train)))\n",
    "    # print(f'vocab: {vocab[10:20]}\\n \\n train: {train[10:20]}')\n",
    "    # print(f'fake id: {words[\"[FAKE]\"]}')\n",
    "    # print(f'real id: {words[\"[REAL]\"]}')\n",
    "\n",
    "    [vocab,words,test] = read_encode(test_name,vocab,words,[],-1)\n",
    "    test_data = torch.tensor(test)\n",
    "\n",
    "    #print('vocab: %d test: %d' % (len(vocab),len(test)))\n",
    "    vocab_size = len(vocab)\n",
    "    train_features, train_targets = process_data(train_data)\n",
    "    #test_features, test_targets = process_data(test_data)\n",
    "    \n",
    "    if model_type == 'FFNN':\n",
    "        ffnn_model = FFNN(vocab, words, d_mod, d_hid, dropout)\n",
    "        optimizer = torch.optim.SGD(ffnn_model.parameters(), lr=0.01, momentum=0.9)\n",
    "        train_loop(ffnn_model, train_features, train_targets, epochs, optimizer)\n",
    "        pass\n",
    "        # print(ffnn_model)\n",
    "#          {add code to instantiate the model, train for K epochs and save model to disk}\n",
    "        \n",
    "    if model_type == 'LSTM':\n",
    "        pass\n",
    "#          {add code to instantiate the model, train for K epochs and save model to disk}\n",
    "\n",
    "    if model_type == 'FFNN_CLASSIFY':\n",
    "        pass\n",
    "#          {add code to instantiate the model, recall model parameters and perform/learn classification}    \n",
    "\n",
    "    if model_type == 'LSTM_CLASSIFY':\n",
    "        pass\n",
    "#          {add code to instantiate the model, recall model parameters and perform/learn classification}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zarif_vfgx7yn\\AppData\\Local\\Temp\\ipykernel_7036\\508513551.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_tensor_list.append(torch.tensor(bio).squeeze())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First bio torch.Size([880])\n",
      "Second bio torch.Size([880])\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.7095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "0\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.7092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "1\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.7085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "2\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.7076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "3\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.7065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "4\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.7053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "5\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.7039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "6\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.7026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "7\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.7012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "8\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "9\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "10\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "11\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "12\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "13\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "14\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "15\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "16\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6935, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "17\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "18\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962, 2])\n",
      "Loss: tensor(0.6927, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "19\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
