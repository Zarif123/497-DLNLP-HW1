{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy Contents to starter.py for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and decoding\n",
    "def decode(vocab,corpus):\n",
    "    \n",
    "    text = ''\n",
    "    for i in range(len(corpus)):\n",
    "        wID = corpus[i]\n",
    "        text = text + vocab[wID] + ' '\n",
    "    return(text)\n",
    "\n",
    "def encode(words,text):\n",
    "    corpus = []\n",
    "    tokens = text.split(' ')\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            wID = words[t][0]\n",
    "        except:\n",
    "            wID = words['<unk>'][0]\n",
    "        corpus.append(wID)\n",
    "    return(corpus)\n",
    "\n",
    "def read_encode(file_name,vocab,words,corpus,threshold):\n",
    "    \n",
    "    wID = len(vocab)\n",
    "    \n",
    "    if threshold > -1:\n",
    "        with open(file_name,'rt', encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                line = line.replace('\\n','')\n",
    "                tokens = line.split(' ')\n",
    "                for t in tokens:\n",
    "                    try:\n",
    "                        elem = words[t]\n",
    "                    except:\n",
    "                        elem = [wID,0]\n",
    "                        vocab.append(t)\n",
    "                        wID = wID + 1\n",
    "                    elem[1] = elem[1] + 1\n",
    "                    words[t] = elem\n",
    "\n",
    "        temp = words\n",
    "        words = {}\n",
    "        vocab = []\n",
    "        wID = 0\n",
    "        words['<unk>'] = [wID,100]\n",
    "        vocab.append('<unk>')\n",
    "        for t in temp:\n",
    "            if temp[t][1] >= threshold:\n",
    "                vocab.append(t)\n",
    "                wID = wID + 1\n",
    "                words[t] = [wID,temp[t][1]]\n",
    "            \n",
    "                    \n",
    "    with open(file_name,'rt', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n','')\n",
    "            tokens = line.split(' ')\n",
    "            for t in tokens:\n",
    "                try:\n",
    "                    wID = words[t][0]\n",
    "                except:\n",
    "                    wID = words['<unk>'][0]\n",
    "                corpus.append(wID)\n",
    "                \n",
    "    return [vocab,words,corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeedForward Model\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, vocab, words, d_model, d_hidden, dropout):\n",
    "        super().__init__() \n",
    "    \n",
    "        # Class parameters\n",
    "        self.vocab = vocab\n",
    "        self.words = words\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.d_model = d_model\n",
    "        self.d_hidden = d_hidden\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Embedding Layer\n",
    "        #self.embeds = nn.Embedding(self.vocab_size, self.d_model)\n",
    "\n",
    "        # Linear Layer\n",
    "        self.fc1 = nn.Linear(880, d_hidden)\n",
    "\n",
    "        # Nonlinear Layer\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(d_hidden, 2)\n",
    "\n",
    "        # Setting weights\n",
    "        self.init_weights()\n",
    "                \n",
    "    # Initialize weights for foward layer\n",
    "    def init_weights(self):\n",
    "        weight_range = 0.1\n",
    "        #self.embeds.weight.data.uniform_(-weight_range, weight_range)\n",
    "        self.fc1.weight.data.uniform_(-weight_range, weight_range)\n",
    "        self.fc1.bias.data.zero_()\n",
    "\n",
    "    # Forward\n",
    "    def forward(self, src):\n",
    "        # Embeddings are fed into the forward layer\n",
    "        #embeds = self.embeds(src)\n",
    "        x = self.activation(self.fc1(src))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,vocab,words,d_model,d_hidden,n_layers,dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Class Parameters\n",
    "        self.vocab = vocab\n",
    "        self.words = words\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.n_layers = n_layers\n",
    "        self.d_hidden = d_hidden\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embeds = nn.Embedding(self.vocab_size,self.d_model)\n",
    "        \n",
    "    # Forward\n",
    "    def forward(self,src,h):\n",
    "        embeds = self.dropout(self.embeds(src))       \n",
    "        return [preds,h]\n",
    "    \n",
    "    def init_weights(self):\n",
    "        pass        \n",
    "    \n",
    "    def detach_hidden(self, hidden):\n",
    "        return [hidden, cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def process_data(data):\n",
    "    fake_i = (data == 122)\n",
    "    real_i = (data == 635)\n",
    "    target_indices = (fake_i + real_i).nonzero()\n",
    "    num_entries = len(target_indices)\n",
    "    bio_tensor_list = []\n",
    "    target_list = []\n",
    "    entry = 0\n",
    "    start_i = 0\n",
    "\n",
    "    while entry < num_entries:\n",
    "            target_i = target_indices[entry]\n",
    "            # Size of data and targets\n",
    "            #print(f\"Data size: {data[start_i:target_i].size()}\")\n",
    "            #print(f\"Target size: {data[target_i].size()}\")\n",
    "\n",
    "            # Take in a list of tensors and use pad sequence\n",
    "            bio = data[start_i:target_i]\n",
    "            target = data[target_i]\n",
    "\n",
    "            bio_tensor_list.append(torch.tensor(bio).squeeze())\n",
    "            target_list.append(target)\n",
    "\n",
    "            start_i = target_i + 1\n",
    "            entry += 1\n",
    "\n",
    "    padded_bios = torch.t(pad_sequence(bio_tensor_list))\n",
    "    print(\"First bio\", padded_bios[0].size())\n",
    "    print(\"Second bio\", padded_bios[1].size())\n",
    "    return padded_bios.float(), torch.tensor(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model Function\n",
    "def train_model(model, features, targets, optimizer):\n",
    "        print(features.size())\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        output = model(features)\n",
    "\n",
    "        # Shapes of output and targets\n",
    "        print(f\"Output size: {output.size()}\")\n",
    "        print(f\"Target size: {targets.size()}\")\n",
    "\n",
    "        \n",
    "        # grossest thing ive ever done\n",
    "        argmax_indices = torch.argmax(output, dim=1)\n",
    "        \n",
    "        print(f\"Target size: {argmax_indices.size(dim=0)}\")\n",
    "        pred = torch.empty(argmax_indices.size(dim=0))\n",
    "        for index in range(argmax_indices.size(dim=0)):\n",
    "            #print(output[index,argmax_indices[index]])\n",
    "            pred[index] = (output[index,argmax_indices[index]])\n",
    "        \n",
    "        #predictions = output[torch.argmax(output)]\n",
    "        \n",
    "        #print(f\"pred\", pred)\n",
    "\n",
    "        loss = F.mse_loss(pred.float(), targets.float())\n",
    "        print(\"Loss:\", loss)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "def train_loop(model, features, targets, epochs, optimizer):\n",
    "    for epoch in range(0, epochs):\n",
    "        train_model(model, features, targets, optimizer)\n",
    "        print(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_map = {0: 'FFNN', 1: 'LSTM', 2: 'FFNN_CLASSIFY', 3: 'LSTM_CLASSIFY'}\n",
    "train_map = {0: 'data/real.train.tok', 1: 'data/fake.train.tok', 2: 'data/mix.train.tok'}\n",
    "valid_map = {0: 'data/real.valid.tok', 1: 'data/fake.valid.tok', 2: 'data/mix.valid.tok'}\n",
    "test_map = {0: 'data/real.test.tok', 1: 'data/fake.test.tok', 2: 'data/mix.test.tok', 3: 'data/blind.test.tok'}\n",
    "\n",
    "model_type = model_map[0]\n",
    "# train_type = [train_map[0], train_map[1]]\n",
    "\n",
    "# Types of data\n",
    "train_type = train_map[2]\n",
    "valid_type = valid_map[0]\n",
    "test_type = test_map[0]\n",
    "\n",
    "args = {\n",
    "    \"d_model\": 1,\n",
    "    \"d_hidden\": 2,\n",
    "    \"n_layers\": 3,\n",
    "    \"batch_size\": 20,\n",
    "    \"seq_len\": 30,\n",
    "    \"printevery\": 5000,\n",
    "    \"window\": 3,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 0.0001,\n",
    "    \"dropout\": 0.35,\n",
    "    \"clip\": 2.0,\n",
    "    \"model\": model_type,\n",
    "    \"savename\": model_type.lower(),\n",
    "    \"loadname\": model_type.lower(),\n",
    "    \"trainname\": train_type,\n",
    "    \"validname\": valid_type,\n",
    "    \"testname\": test_type\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function\n",
    "def main(args): \n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    params = Params(**args)\n",
    "    train_name = params.trainname\n",
    "    test_name = params.testname\n",
    "    model_type = params.model\n",
    "    d_mod = params.d_model\n",
    "    d_hid = params.d_hidden\n",
    "    dropout = params.dropout\n",
    "    epochs = params.epochs\n",
    "\n",
    "    # real, fake = params.trainname\n",
    "    # [vocab_real, words_real, train_real] = read_encode(real, [], {}, [], 3)\n",
    "    # [vocab_fake, words_fake, train_fake] = read_encode(fake, [], {}, [], 3)\n",
    "\n",
    "    # train_features = torch.cat((torch.tensor(train_real), torch.tensor(train_fake)))\n",
    "    # train_labels = torch.cat((torch.ones(len(train_real)), torch.zeros(len(train_fake))))\n",
    "    # print(f'train_features: {train_features}')\n",
    "    # print(f'train_labels: {train_labels}')\n",
    "\n",
    "    [vocab,words,train] = read_encode(train_name,[],{},[],3)\n",
    "    train_data = torch.tensor(train)\n",
    "    \n",
    "    # print('vocab: %d train: %d' % (len(vocab),len(train)))\n",
    "    # print(f'vocab: {vocab[10:20]}\\n \\n train: {train[10:20]}')\n",
    "    # print(f'fake id: {words[\"[FAKE]\"]}')\n",
    "    # print(f'real id: {words[\"[REAL]\"]}')\n",
    "\n",
    "    [vocab,words,test] = read_encode(test_name,vocab,words,[],-1)\n",
    "    test_data = torch.tensor(test)\n",
    "\n",
    "    #print('vocab: %d test: %d' % (len(vocab),len(test)))\n",
    "    vocab_size = len(vocab)\n",
    "    train_features, train_targets = process_data(train_data)\n",
    "    #test_features, test_targets = process_data(test_data)\n",
    "    \n",
    "    if model_type == 'FFNN':\n",
    "        ffnn_model = FFNN(vocab, words, d_mod, d_hid, dropout)\n",
    "        optimizer = torch.optim.SGD(ffnn_model.parameters(), lr=0.01, momentum=0.9)\n",
    "        train_loop(ffnn_model, train_features, train_targets, epochs, optimizer)\n",
    "        pass\n",
    "        # print(ffnn_model)\n",
    "#          {add code to instantiate the model, train for K epochs and save model to disk}\n",
    "        \n",
    "    if model_type == 'LSTM':\n",
    "        pass\n",
    "#          {add code to instantiate the model, train for K epochs and save model to disk}\n",
    "\n",
    "    if model_type == 'FFNN_CLASSIFY':\n",
    "        pass\n",
    "#          {add code to instantiate the model, recall model parameters and perform/learn classification}    \n",
    "\n",
    "    if model_type == 'LSTM_CLASSIFY':\n",
    "        pass\n",
    "#          {add code to instantiate the model, recal l model parameters and perform/learn classification}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seand\\miniconda3\\envs\\hw6-neural\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First bio torch.Size([880])\n",
      "Second bio torch.Size([880])\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(5923447.5000, grad_fn=<MseLossBackward0>)\n",
      "0\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(3.8013e+27, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(240945.9062, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(246954.4688, grad_fn=<MseLossBackward0>)\n",
      "3\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(245164.9219, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(236490.2031, grad_fn=<MseLossBackward0>)\n",
      "5\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(222260.5156, grad_fn=<MseLossBackward0>)\n",
      "6\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(204036.8594, grad_fn=<MseLossBackward0>)\n",
      "7\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(183442.4062, grad_fn=<MseLossBackward0>)\n",
      "8\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(162022.7031, grad_fn=<MseLossBackward0>)\n",
      "9\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(141138.0469, grad_fn=<MseLossBackward0>)\n",
      "10\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(121891.5234, grad_fn=<MseLossBackward0>)\n",
      "11\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(105090.1328, grad_fn=<MseLossBackward0>)\n",
      "12\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(91236.3906, grad_fn=<MseLossBackward0>)\n",
      "13\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(80544.8750, grad_fn=<MseLossBackward0>)\n",
      "14\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(72977.4609, grad_fn=<MseLossBackward0>)\n",
      "15\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(68291.7656, grad_fn=<MseLossBackward0>)\n",
      "16\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(66095.6094, grad_fn=<MseLossBackward0>)\n",
      "17\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(65903.0938, grad_fn=<MseLossBackward0>)\n",
      "18\n",
      "torch.Size([7962, 880])\n",
      "Output size: torch.Size([7962, 2])\n",
      "Target size: torch.Size([7962])\n",
      "Target size: 7962\n",
      "Loss: tensor(67186.9375, grad_fn=<MseLossBackward0>)\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "442abea20ed451c67da84ff3aae222d2074d2823dd745c8c50b7b46ab6ec4fe4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
